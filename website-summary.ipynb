{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7549d8d-570f-454b-8a2e-97cbd0b3e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2808e2af-1b43-46cd-b626-2cb72bcadee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining headers \n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76670bc5-f154-4445-adc1-2092d1a4a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.base_url = url\n",
    "        self.visited = set()\n",
    "        self.headers = headers\n",
    "        self.all_texts = []   # to store all page texts\n",
    "        self.crawl(url)\n",
    "        self.text = \"\\n\\n\".join(page_text for _, page_text in self.all_texts)  # After crawling, create a combined text\n",
    "        \n",
    "    def crawl(self, url): #crawl all the links within the site\n",
    "        if url in self.visited:\n",
    "            return\n",
    "        print(f\"Crawling: {url} (Visited {len(self.visited)} pages so far)\")\n",
    "\n",
    "        \n",
    "        self.visited.add(url)\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=5)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Save the page title and cleaned text\n",
    "            title = soup.title.string if soup.title else \"No title found\"\n",
    "            \n",
    "            # Set self.title once, from the homepage\n",
    "            if not hasattr(self, 'title'):\n",
    "                self.title = title\n",
    "                \n",
    "            for irrevelent in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrevelent.decompose()\n",
    "            text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            self.all_texts.append((title, text))\n",
    "            \n",
    "            # Find all links\n",
    "            for link_tag in soup.find_all('a', href=True):\n",
    "                href = link_tag['href']\n",
    "                full_url = urljoin(url, href)  # join relative links to base\n",
    "                \n",
    "                # Stay within the same domain\n",
    "                if self.is_internal(full_url):\n",
    "                    self.crawl(full_url)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to crawl {url}: {e}\")\n",
    "    \n",
    "    def is_internal(self, url):\n",
    "        # Make sure the link is from the same domain\n",
    "        base_domain = urlparse(self.base_url).netloc\n",
    "        link_domain = urlparse(url).netloc\n",
    "        return base_domain == link_domain\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1255a438-05dc-44d1-a461-07565283539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://roshanchaudhary001.com.np/ (Visited 0 pages so far)\n",
      "Crawling: https://roshanchaudhary001.com.np/About (Visited 1 pages so far)\n",
      "Crawling: https://roshanchaudhary001.com.np/Projects (Visited 2 pages so far)\n",
      "Crawling: https://roshanchaudhary001.com.np/Blogs (Visited 3 pages so far)\n",
      "Crawling: https://roshanchaudhary001.com.np/roshan_new_cv.pdf (Visited 4 pages so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to crawl https://roshanchaudhary001.com.np/roshan_new_cv.pdf: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "site = Website(\"https://roshanchaudhary001.com.np/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef591c28-3631-4697-9077-1b438af6720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system prompt for model\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9103b26a-cf36-4af4-b000-7de780b24be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53dcbb62-33e9-4084-ad42-1f6f4ef94586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'You are looking at a website titled Roshan Chaudhary\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nAbout\\nProjects\\nBlogs\\nDownload CV\\nHi, my name is\\nRoshan Chaudhary.\\nAspiring Software Developer.\\nI\\'m a software engineer specializing in building (and occasionally designing) exceptional digital experiences. Currently, I\\'m focused on building accessible, human-centered products.\\nSee More About Me\\n\\nAbout\\nProjects\\nBlogs\\nDownload CV\\nHello! My name is\\nRoshan Chaudhary\\nand I am currently learning software development and how things work around in the world of computer. I am proficient in frontend as well as backend with 1.5 yrs of experience. My primary proficiency is in Javascript. You can reach me at\\nroshanchau001@gmail.com\\nHere are some technologies that I use recently:\\nJavascript\\nTypescript\\nReact\\nNextJS\\nNode.js\\nExpress\\nMySQL\\nMongodb\\n\\nAbout\\nProjects\\nBlogs\\nDownload CV\\n\\nAbout\\nProjects\\nBlogs\\nDownload CV\\nBlogs\\ntitle: \"Scaling Node.js Application Using Clustering and PM2\"\\ndate: \"2025-04-19\"\\ndescription: \"Learn how to scale a Node.js app using the Cluster module and PM2 process manager for better performance and reliability.\"\\npublished: true\\nimage: \"/images/nodejs-scaling.png\"\\nWhen you run a Node.js program on a system with multiple CPUs, it creates a process that uses only a single CPU to execute by default.\\nSince Node.js uses a single thread to execute your JavaScript code, all the requests to the application have to be handled by that thread running on a single CPU.\\nIf the application has CPU-intensive tasks, the operating system has to schedule them to share a single CPU until completion. That can result in a single process getting overwhelmed if it receives too many requests, which can slow down the performance. If the process crashes, users won’t be able to access your application.\\nAs a solution, Node.js introduced the\\ncluster\\nmodule, which creates multiple copies of the same application on the same machine and has them running at the same time.\\nIt also comes with a load balancer that evenly distributes the load among the processes using the round-robin algorithm. If a single instance crashes, users can be served by the remaining processes that are still running.\\nThe application’s performance significantly improves because the load is shared among multiple processes evenly, preventing a single instance from being overwhelmed.'}]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": user_prompt_for(site)\n",
    "    }\n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f318b355-c34b-43ba-9fad-ed42850c4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now importing ollama locally\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e4a562b1-5975-419c-bb72-5de619552f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\" #i have this model in my device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "240c04d9-2522-4cca-8726-67313e7042b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary of Roshan Chaudhary's Website**\n",
      "=====================================\n",
      "\n",
      "### About\n",
      "\n",
      "* Roshan Chaudhary is an aspiring software developer with expertise in building accessible and human-centered digital experiences.\n",
      "\n",
      "### Projects\n",
      "\n",
      "* Currently focused on building accessible products\n",
      "* No specific projects listed\n",
      "\n",
      "### Blogs\n",
      "\n",
      "* Published a blog post titled \"Scaling Node.js Application Using Clustering and PM2\" on April 19, 2025\n",
      "* The blog post explains how to scale a Node.js app using the Cluster module and PM2 process manager for better performance and reliability.\n",
      "\n",
      "### News/Announcements\n",
      "\n",
      "* No recent news or announcements are available on this website.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d7a87-42de-42a7-9766-056eea7ead0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
