{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7549d8d-570f-454b-8a2e-97cbd0b3e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2808e2af-1b43-46cd-b626-2cb72bcadee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining headers \n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76670bc5-f154-4445-adc1-2092d1a4a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.base_url = url\n",
    "        self.visited = set()\n",
    "        self.headers = headers\n",
    "        self.all_texts = []   # to store all page texts\n",
    "        self.crawl(url)\n",
    "        self.text = \"\\n\\n\".join(page_text for _, page_text in self.all_texts)  # After crawling, create a combined text\n",
    "        \n",
    "    def crawl(self, url): #crawl all the links within the site\n",
    "        if url in self.visited:\n",
    "            return\n",
    "        print(f\"Crawling: {url} (Visited {len(self.visited)} pages so far)\")\n",
    "\n",
    "        \n",
    "        self.visited.add(url)\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=5)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Save the page title and cleaned text\n",
    "            title = soup.title.string if soup.title else \"No title found\"\n",
    "            \n",
    "            # Set self.title once, from the homepage\n",
    "            if not hasattr(self, 'title'):\n",
    "                self.title = title\n",
    "                \n",
    "            for irrevelent in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrevelent.decompose()\n",
    "            text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            self.all_texts.append((title, text))\n",
    "            \n",
    "            # Find all links\n",
    "            for link_tag in soup.find_all('a', href=True):\n",
    "                href = link_tag['href']\n",
    "                full_url = urljoin(url, href)  # join relative links to base\n",
    "                \n",
    "                # Stay within the same domain\n",
    "                if self.is_internal(full_url):\n",
    "                    self.crawl(full_url)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to crawl {url}: {e}\")\n",
    "    \n",
    "    def is_internal(self, url):\n",
    "        # Make sure the link is from the same domain\n",
    "        base_domain = urlparse(self.base_url).netloc\n",
    "        link_domain = urlparse(url).netloc\n",
    "        return base_domain == link_domain\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1255a438-05dc-44d1-a461-07565283539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://roshanchaudhary001.com.np/ (Visited 0 pages so far)\n",
      "Crawling: https://roshanchaudhary001.com.np/About (Visited 1 pages so far)\n",
      "Crawling: https://roshanchaudhary001.com.np/Projects (Visited 2 pages so far)\n",
      "Crawling: https://roshanchaudhary001.com.np/Blogs (Visited 3 pages so far)\n",
      "Crawling: https://roshanchaudhary001.com.np/roshan_new_cv.pdf (Visited 4 pages so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to crawl https://roshanchaudhary001.com.np/roshan_new_cv.pdf: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "site = Website(\"https://roshanchaudhary001.com.np/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ef591c28-3631-4697-9077-1b438af6720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system prompt for model\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9103b26a-cf36-4af4-b000-7de780b24be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "53dcbb62-33e9-4084-ad42-1f6f4ef94586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Website' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m messages = [\n\u001b[32m      2\u001b[39m     {\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43muser_prompt_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     }\n\u001b[32m      6\u001b[39m ]\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(messages)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36muser_prompt_for\u001b[39m\u001b[34m(website)\u001b[39m\n\u001b[32m      4\u001b[39m     user_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou are looking at a website titled \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwebsite.title\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m     user_prompt += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThe contents of this website is as follows; \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33mplease provide a short summary of this website in markdown. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33mIf it includes news or announcements, then summarize these too.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     user_prompt += \u001b[43mwebsite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m user_prompt\n",
      "\u001b[31mAttributeError\u001b[39m: 'Website' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": user_prompt_for(site)\n",
    "    }\n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f318b355-c34b-43ba-9fad-ed42850c4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now importing ollama locally\n",
    "import ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a562b1-5975-419c-bb72-5de619552f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\" #i have this model in my device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "240c04d9-2522-4cca-8726-67313e7042b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**No Title Found Website Summary**\n",
      "\n",
      "### Overview\n",
      "\n",
      "The website \"No title found\" appears to be a cybersecurity awareness and education platform focused on helping individuals and organizations protect themselves from cyber threats.\n",
      "\n",
      "### Features\n",
      "\n",
      "* **Tools**: The website offers various tools, including:\n",
      "\t+ Find My IP: to check the user's public IP address\n",
      "\t+ Cyber Leak Checker: to check if email or personal information has been compromised in known data breaches\n",
      "\t+ Is My Website Compromised?: to perform basic security checks on a website\n",
      "* **Reporting**: Users can report suspected cybercrime through a chatbot for further investigation and action.\n",
      "* **Training**: The platform provides training sessions on cybersecurity best practices, including phishing email simulators and incident response plans.\n",
      "\n",
      "### News and Announcements\n",
      "\n",
      "* A breach alert system has been launched to notify users of potential security threats.\n",
      "* Cyber Alert Nepal has been featured in various media outlets for its work in cybersecurity awareness, training, and incident response.\n",
      "* The organization is committed to creating a safer digital environment for every Nepali, with a focus on empowering individuals and organizations with tools, knowledge, and support.\n",
      "\n",
      "### Quotes\n",
      "\n",
      "* \"Cyber Alert Nepal has been making a significant impact in cyber hygiene and digital safety.\"\n",
      "* \"Our mission is clear: to create a safer digital environment for every Nepali.\"\n",
      "\n",
      "Note: The website appears to be focused on promoting cybersecurity awareness and education, rather than providing news or announcements.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d7a87-42de-42a7-9766-056eea7ead0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
